# -*- coding: utf-8 -*-
"""IDCamp_Submission_Machine Learning.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1xIfPClwTEpoEjext4lwY0t8QMQ3hbIhd

*   Nama Lengkap : Adisaputra Zidha Noorizki
*   Username     : hi_zidha
*   Email        : hi.zidha@gmail.com
"""

!pip install tensorflow
!pip install keras
!wget --no-check-certificate \https://github.com/dicodingacademy/assets/releases/download/release/rockpaperscissors.zip -O /tmp/rockpaperscissors.zip

import tensorflow as tf
print(tf.__version__)

import zipfile, os
local_zip = '/tmp/rockpaperscissors.zip'
zip_ref = zipfile.ZipFile(local_zip, 'r')
zip_ref.extractall('/tmp')
zip_ref.close()

base_dir = '/tmp/rockpaperscissors/rps-cv-images'

file_list = os.listdir(base_dir)
for file in file_list:
    print(file)

!pip install split-folders

import splitfolders

input_folder = base_dir
output_folder = '/tmp/rockpaperscissors/dataset'

splitfolders.ratio(input_folder,
                   output_folder,
                   seed=42,
                   ratio=(0.6, 0.4))

train_dir = output_folder+'/train'
val_dir   = output_folder+'/val'

os.listdir(train_dir)

os.listdir(val_dir)

import cv2
import numpy as np
from PIL import Image

def rotate_image(image, angle):
    image = Image.fromarray(image)
    rotated_image = image.rotate(angle)
    return cv2.cvtColor(np.array(rotated_image), cv2.COLOR_RGB2BGR)

augmentation_dir = '/tmp/rockpaperscissors/aug_train'
os.makedirs(augmentation_dir, exist_ok=True)

angle = 10
categories = os.listdir(train_dir)
for category in categories:
    os.makedirs(os.path.join(augmentation_dir, category), exist_ok=True)

for category in categories:
    category_dir = os.path.join(train_dir, category)
    image_files = os.listdir(category_dir)

    for image_file in image_files:
        image_path = os.path.join(category_dir, image_file)
        image = cv2.imread(image_path)

        augmented_image = rotate_image(image, angle)
        augmented_image_path = os.path.join(augmentation_dir, category, image_file)
        cv2.imwrite(augmented_image_path, augmented_image)

from keras.preprocessing.image import ImageDataGenerator

train_datagen = ImageDataGenerator(
                        rescale=1./255,
                        rotation_range=20,
                        horizontal_flip=True,
                        shear_range = 0.2,
                        fill_mode = 'nearest')

test_datagen = ImageDataGenerator(rescale=1./255)

train_generator = train_datagen.flow_from_directory(
            augmentation_dir,
            target_size=(150, 150),
            batch_size=4,
            class_mode='categorical')

validation_generator = test_datagen.flow_from_directory(
            val_dir,
            target_size=(150, 150),
            batch_size=4,
            class_mode='categorical')

early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)
model_checkpoint = tf.keras.callbacks.ModelCheckpoint('best_model.h5', save_best_only=True)
tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir='./logs', histogram_freq=1)

# Inisialisasi model
model = tf.keras.models.Sequential([
        tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(150, 150, 3)),
        tf.keras.layers.MaxPooling2D(2, 2),
        tf.keras.layers.Conv2D(64, (3,3), activation='relu'),
        tf.keras.layers.MaxPooling2D(2,2),
        tf.keras.layers.Conv2D(128, (3,3), activation='relu'),
        tf.keras.layers.MaxPooling2D(2,2),
        tf.keras.layers.Conv2D(512, (3,3), activation='relu'),
        tf.keras.layers.MaxPooling2D(2,2),
        tf.keras.layers.Flatten(),
        tf.keras.layers.Dense(512, activation='relu'),
        tf.keras.layers.Dense(3, activation='softmax')
    ])

model.summary()

model.compile(optimizer=tf.optimizers.Adam(learning_rate=0.001),
              loss='categorical_crossentropy',
              metrics=['accuracy'])

history = model.fit(
    train_generator,
    steps_per_epoch=35,
    validation_data=validation_generator,
    validation_steps=7,
    epochs=25,
    callbacks=[early_stopping, model_checkpoint, tensorboard_callback]
)

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
from google.colab import files
from keras.preprocessing import image
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
# %matplotlib inline

uploaded = files.upload()

for fn in uploaded.keys():
  # predicting images
  path = fn
  img = image.load_img(path, target_size=(150, 150))

  imgplot = plt.imshow(img)
  x = image.img_to_array(img)
  x = np.expand_dims(x, axis=0)
  images = np.vstack([x])

  # Prediksi kelas dengan probabilitas tertinggi
  classes = model.predict(images, batch_size=10)
  predicted_class = np.argmax(classes)

  class_labels = ['paper', 'rock', 'scissors']
  print(fn)
  print(class_labels[predicted_class])

uploaded = files.upload()

for fn in uploaded.keys():
  # predicting images
  path = fn
  img = image.load_img(path, target_size=(150, 150))

  imgplot = plt.imshow(img)
  x = image.img_to_array(img)
  x = np.expand_dims(x, axis=0)
  images = np.vstack([x])

  # Prediksi kelas dengan probabilitas tertinggi
  classes = model.predict(images, batch_size=10)
  predicted_class = np.argmax(classes)

  class_labels = ['paper', 'rock', 'scissors']
  print(fn)
  print(class_labels[predicted_class])